{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     27\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs,labels)\n\u001b[0;32m---> 28\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     29\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py:401\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=391'>392</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=392'>393</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=393'>394</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=394'>395</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=398'>399</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=399'>400</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/_tensor.py?line=400'>401</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=185'>186</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=187'>188</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=188'>189</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=189'>190</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=190'>191</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=191'>192</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Users/eunsoo/miniforge3/envs/pytorch-dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=192'>193</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "data_path = './open/'\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path+'test.csv')\n",
    "valid = pd.read_csv(data_path+'val.csv')\n",
    "submission =pd.read_csv(data_path+'sample_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### isolate forest #####\n",
    "#TODO : 앙상블, grid search\n",
    "train_droped = train.drop('ID',axis=1)\n",
    "sample = train_droped.sample(frac = 0.1)\n",
    "\n",
    "valid_droped = valid.drop(['ID','Class'],axis=1)\n",
    "\n",
    "val_normal, val_fraud = valid['Class'].value_counts()\n",
    "val_contamination = val_fraud / val_normal\n",
    "\n",
    "N_ITER = 300\n",
    "#train\n",
    "iso_classifiers= IsolationForest(n_estimators=N_ITER, max_samples=len(sample),contamination=val_contamination).fit(sample)\n",
    "\n",
    "y_prediction = iso_classifiers.predict(sample)\n",
    "y_prediction[y_prediction==1] = 0\n",
    "y_prediction[y_prediction==-1] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid\n",
    "valid_predict = iso_classifiers.predict(valid_droped)\n",
    "valid_predict[valid_predict==1] = 0\n",
    "valid_predict[valid_predict==-1] = 1\n",
    "valid_label = valid['Class']\n",
    "val_score = f1_score(valid_label,valid_predict,average='macro')\n",
    "print(f'val f1 : {val_score}')\n",
    "print(classification_report(valid_label, valid_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "test_droped = test.drop(['ID'],axis=1)\n",
    "iso_test_predict = iso_classifiers.predict(test_droped)\n",
    "iso_test_predict[iso_test_predict==1] = 0\n",
    "iso_test_predict[iso_test_predict==-1] = 1\n",
    "# sub_df = pd.DataFrame(submission, columns = ['Class'])\n",
    "#  = pd.concat([sub_df['ID'],df['Class']],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Autoencoder ####\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error # Regression 문제의 평가를 위해 MSE(Mean Squared Error)를 불러온다.\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "data_path = './open/'\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path+'test.csv')\n",
    "valid = pd.read_csv(data_path+'val.csv')\n",
    "submission =pd.read_csv(data_path+'sample_submission.csv')\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "Epochs =200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('normalizer', Normalizer()),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "valid_droped = valid.drop(['ID','Class'],axis=1)\n",
    "train_droped = train.drop('ID',axis=1)\n",
    "pipeline.fit(train_droped)\n",
    "pipeline.fit(valid_droped)\n",
    "\n",
    "train_transformed = pipeline.transform(train_droped)\n",
    "valid_transformed = pipeline.transform(valid_droped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TensorData(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = TensorData(train_transformed, train_transformed)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "validset = TensorData(valid_transformed, valid_transformed)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL\n",
    "    \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "                        nn.Linear(input_dim, 16, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16, 8, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(8, 4, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(4, 2, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                    \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "                        nn.Linear(2, 4, bias=True),\n",
    "                        nn.ReLU(),  \n",
    "                        nn.Linear(4, 8, bias=True),\n",
    "                        nn.ReLU(),  \n",
    "                        nn.Linear(8, 16, bias=True),\n",
    "                        nn.ReLU(),  \n",
    "                        nn.Linear(16, input_dim, bias=True),\n",
    "                        nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_transformed.shape[1]\n",
    "model = Autoencoder(input_dim).to(device)\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps = len(trainloader)*3,num_training_steps = len(trainloader)*Epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_min_score = np.inf\n",
    "fraud_labels = valid['Class']\n",
    "\n",
    "def calF1score(pres,labels,THRESHOLD):\n",
    "  preds_np = np.array(pres)\n",
    "  trues_np = np.array(labels)\n",
    "  mse = np.mean(np.power(preds_np - trues_np, 2), axis=1)\n",
    " \n",
    "  m = np.median(mse)\n",
    "  ad = np.abs(mse - m)\n",
    "  mad = np.median(ad)\n",
    "  z_scores = 0.6745 * ad / mad\n",
    "  outliers = np.where(z_scores>THRESHOLD,1,0 )\n",
    "  return outliers\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  preds_list =[]\n",
    "  label_list = []\n",
    "  for inputs,labels in trainloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs,labels)\n",
    "    loss.backward()\n",
    "    train_loss +=loss.item()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "  if epoch %5 ==0:\n",
    "    print(f'{epoch+1} train loss : {train_loss/len(trainloader):.4f}')\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      for inputs,labels in validloader:\n",
    "         \n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = model(inputs)\n",
    "      \n",
    "          pres = outputs.cpu().numpy()\n",
    "          # print(pres)\n",
    "          preds_list.extend(pres)\n",
    "          \n",
    "          true_value = labels.cpu().numpy()\n",
    "          label_list.extend(true_value)\n",
    "      fraud_pres = calF1score(preds_list,label_list,3)\n",
    "      val_score = f1_score(fraud_labels,valid_predict,average='macro')\n",
    "\n",
    "  print(f'valid f1 : {val_score:.4f} , iter : {epoch}')\n",
    "  if val_score<=f1_min_score:\n",
    "    print(\"save model..\")\n",
    "    torch.save(model.state_dict(),'./model_state_dict.pth')\n",
    "    f1_min_score = val_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_droped = test.drop('ID',axis=1)\n",
    "\n",
    "test_transformed = pipeline.transform(test_droped)\n",
    "submission_data = TensorData(test_transformed, test_transformed)\n",
    "submissionloader = torch.utils.data.DataLoader(submission_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# X_valid_transformed = pipeline.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error # Regression 문제의 평가를 위해 MSE(Mean Squared Error)를 불러온다.\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "epoch_valid_loss = 0\n",
    "preds_list =[]\n",
    "label_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in submissionloader:\n",
    "        inputs, values = data\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        preds = outputs.cpu().numpy()\n",
    "        preds_list.extend(preds)\n",
    "        trues = values.cpu().numpy()\n",
    "        label_list.extend(trues)\n",
    "    \n",
    "auto_pred = calF1score(preds_list,label_list,3)\n",
    "\n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "torch.save({'model':model.state_dict(),\n",
    "            'optimizer':optimizer.state_dict()},\n",
    "           path+'autoencoder.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_path = './autoencoder.tar'\n",
    "checkpoint = torch.load(model_load_path)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pred = pd.DataFrame(outliers,columns=['Class'])\n",
    "auto_pred.head()\n",
    "sumission_auto = pd.concat([submission['ID'],auto_pred['Class']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumission_auto.head()\n",
    "sumission_auto.to_csv('auto_submission.csv',index=False)\n",
    "\n",
    "# sumission_auto.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "680bb6621445d399c41e34df1e719aa22a4edaf485ea1a3c452e97f081b35b9e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
